{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用Python3.5.2（Anaconda）开发，TensorFlow版本是："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经网络的配置\n",
    "\n",
    "方便起见，在这里定义神经网络的配置，你可以很容易找到或改变这些数值，然后重新运行Notebook。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Layer 1.\n",
    "filter_size1 = 5          # Convolution filters are 5 x 5 pixels.\n",
    "num_filters1 = 16         # There are 16 of these filters.\n",
    "\n",
    "# Convolutional Layer 2.\n",
    "filter_size2 = 5          # Convolution filters are 5 x 5 pixels.\n",
    "num_filters2 = 36         # There are 36 of these filters.\n",
    "\n",
    "# Fully-connected layer.\n",
    "fc_size = 128             # Number of neurons in fully-connected layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 载入数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST数据集大约12MB，如果没在文件夹中找到就会自动下载。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"data/train.csv\")\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# trainLabels is y_train\n",
    "train[\"label\"] = train[\"label\"].astype('int32')\n",
    "trainLabels = train[\"label\"]\n",
    "\n",
    "# Drop 'label' column\n",
    "# train pixels is x_train\n",
    "trainPixels = train.drop(labels = [\"label\"],axis = 1)\n",
    "# free some space\n",
    "del train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPixels = trainPixels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as ses:\n",
    "    NUM_CLASSES = 10\n",
    "\n",
    "    labels = trainLabels\n",
    "    onehot_labels = tf.one_hot(labels, depth=10, on_value=None, off_value=None, axis=None, dtype=None, name=None).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在下面的源码中，有很多地方用到了数据维度。它们只在一个地方定义，因此我们可以在代码中使用这些数字而不是直接写数字。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We know that MNIST images are 28 pixels in each dimension.\n",
    "img_size = 28\n",
    "\n",
    "# Images are stored in one-dimensional arrays of this length.\n",
    "img_size_flat = img_size * img_size\n",
    "\n",
    "# Tuple with height and width of images used to reshape arrays.\n",
    "img_shape = (img_size, img_size)\n",
    "\n",
    "# Number of colour channels for the images: 1 channel for gray-scale.\n",
    "num_channels = 1\n",
    "\n",
    "# Number of classes, one class for each of 10 digits.\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "函数用来根据给定大小创建TensorFlow变量，并将它们用随机值初始化。需注意的是在此时并未完成初始化工作，仅仅是在TensorFlow图里定义它们。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_biases(length):\n",
    "    return tf.Variable(tf.constant(0.05, shape=[length]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建卷积层的帮助函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个函数为TensorFlow在计算图里创建了新的卷积层。这里并没有执行什么计算，只是在TensorFlow图里添加了数学公式。\n",
    "\n",
    "假设输入的是四维的张量，各个维度如下：\n",
    "\n",
    "1. 图像数量\n",
    "2. 每张图像的Y轴\n",
    "3. 每张图像的X轴\n",
    "4. 每张图像的通道数\n",
    "\n",
    "输入通道可能是彩色通道，当输入是前面的卷积层生成的时候，它也可能是滤波通道。\n",
    "\n",
    "输出是另外一个4通道的张量，如下：\n",
    "\n",
    "1. 图像数量，与输入相同\n",
    "2. 每张图像的Y轴。如果用到了2x2的池化，是输入图像宽高的一半。\n",
    "3. 每张图像的X轴。同上。\n",
    "4. 卷积滤波生成的通道数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_conv_layer(input,              # The previous layer.\n",
    "                   num_input_channels, # Num. channels in prev. layer.\n",
    "                   filter_size,        # Width and height of each filter.\n",
    "                   num_filters,        # Number of filters.\n",
    "                   use_pooling=True):  # Use 2x2 max-pooling.\n",
    "\n",
    "    # Shape of the filter-weights for the convolution.\n",
    "    # This format is determined by the TensorFlow API.\n",
    "    shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "\n",
    "    # Create new weights aka. filters with the given shape.\n",
    "    weights = new_weights(shape=shape)\n",
    "\n",
    "    # Create new biases, one for each filter.\n",
    "    biases = new_biases(length=num_filters)\n",
    "\n",
    "    # Create the TensorFlow operation for convolution.\n",
    "    # Note the strides are set to 1 in all dimensions.\n",
    "    # The first and last stride must always be 1,\n",
    "    # because the first is for the image-number and\n",
    "    # the last is for the input-channel.\n",
    "    # But e.g. strides=[1, 2, 2, 1] would mean that the filter\n",
    "    # is moved 2 pixels across the x- and y-axis of the image.\n",
    "    # The padding is set to 'SAME' which means the input image\n",
    "    # is padded with zeroes so the size of the output is the same.\n",
    "    layer = tf.nn.conv2d(input=input,\n",
    "                         filter=weights,\n",
    "                         strides=[1, 1, 1, 1],\n",
    "                         padding='SAME')\n",
    "\n",
    "    # Add the biases to the results of the convolution.\n",
    "    # A bias-value is added to each filter-channel.\n",
    "    layer += biases\n",
    "\n",
    "    # Use pooling to down-sample the image resolution?\n",
    "    if use_pooling:\n",
    "        # This is 2x2 max-pooling, which means that we\n",
    "        # consider 2x2 windows and select the largest value\n",
    "        # in each window. Then we move 2 pixels to the next window.\n",
    "        layer = tf.nn.max_pool(value=layer,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME')\n",
    "\n",
    "    # Rectified Linear Unit (ReLU).\n",
    "    # It calculates max(x, 0) for each input pixel x.\n",
    "    # This adds some non-linearity to the formula and allows us\n",
    "    # to learn more complicated functions.\n",
    "    layer = tf.nn.relu(layer)\n",
    "\n",
    "    # Note that ReLU is normally executed before the pooling,\n",
    "    # but since relu(max_pool(x)) == max_pool(relu(x)) we can\n",
    "    # save 75% of the relu-operations by max-pooling first.\n",
    "\n",
    "    # We return both the resulting layer and the filter-weights\n",
    "    # because we will plot the weights later.\n",
    "    return layer, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 转换一个层的帮助函数\n",
    "\n",
    "卷积层生成了4维的张量。我们会在卷积层之后添加一个全连接层，因此我们需要将这个4维的张量转换成可被全连接层使用的2维张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_layer(layer):\n",
    "    # Get the shape of the input layer.\n",
    "    layer_shape = layer.get_shape()\n",
    "\n",
    "    # The shape of the input layer is assumed to be:\n",
    "    # layer_shape == [num_images, img_height, img_width, num_channels]\n",
    "\n",
    "    # The number of features is: img_height * img_width * num_channels\n",
    "    # We can use a function from TensorFlow to calculate this.\n",
    "    num_features = layer_shape[1:4].num_elements()\n",
    "    \n",
    "    # Reshape the layer to [num_images, num_features].\n",
    "    # Note that we just set the size of the second dimension\n",
    "    # to num_features and the size of the first dimension to -1\n",
    "    # which means the size in that dimension is calculated\n",
    "    # so the total size of the tensor is unchanged from the reshaping.\n",
    "    layer_flat = tf.reshape(layer, [-1, num_features])\n",
    "\n",
    "    # The shape of the flattened layer is now:\n",
    "    # [num_images, img_height * img_width * num_channels]\n",
    "\n",
    "    # Return both the flattened layer and the number of features.\n",
    "    return layer_flat, num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建一个全连接层的帮助函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个函数为TensorFlow在计算图中创建了一个全连接层。这里也不进行任何计算，只是往TensorFlow图中添加数学公式。\n",
    "\n",
    "输入是大小为`[num_images, num_inputs]`的二维张量。输出是大小为`[num_images, num_outputs]`的2维张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_fc_layer(input,          # The previous layer.\n",
    "                 num_inputs,     # Num. inputs from prev. layer.\n",
    "                 num_outputs,    # Num. outputs.\n",
    "                 use_relu=True): # Use Rectified Linear Unit (ReLU)?\n",
    "\n",
    "    # Create new weights and biases.\n",
    "    weights = new_weights(shape=[num_inputs, num_outputs])\n",
    "    biases = new_biases(length=num_outputs)\n",
    "\n",
    "    # Calculate the layer as the matrix multiplication of\n",
    "    # the input and weights, and then add the bias-values.\n",
    "    layer = tf.matmul(input, weights) + biases\n",
    "\n",
    "    # Use ReLU?\n",
    "    if use_relu:\n",
    "        layer = tf.nn.relu(layer)\n",
    "\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 占位符 （Placeholder）变量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Placeholder是作为图的输入，每次我们运行图的时候都可能会改变它们。将这个过程称为feeding placeholder变量，后面将会描述它。\n",
    "\n",
    "首先我们为输入图像定义placeholder变量。这让我们可以改变输入到TensorFlow图中的图像。这也是一个张量（tensor），代表一个多维向量或矩阵。数据类型设置为float32，形状设为`[None, img_size_flat]`，`None`代表tensor可能保存着任意数量的图像，每张图象是一个长度为`img_size_flat`的向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "卷积层希望`x`被编码为4维张量，因此我们需要将它的形状转换至`[num_images, img_height, img_width, num_channels]`。注意`img_height == img_width == img_size`，如果第一维的大小设为-1， `num_images`的大小也会被自动推导出来。转换运算如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x, [-1, img_size, img_size, num_channels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我们为输入变量`x`中的图像所对应的真实标签定义placeholder变量。变量的形状是`[None, num_classes]`，这代表着它保存了任意数量的标签，每个标签是长度为`num_classes`的向量，本例中长度为10。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = tf.placeholder(tf.float32, shape=[None, 10], name='y_true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们也可以为class-number提供一个placeholder，但这里用argmax来计算它。这里只是TensorFlow中的一些操作，没有执行什么运算。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.argmax(array, dimension=1) = np.argmax(array, axis=1)<p>\n",
    "如果array是多维数组，dimemsion或axis=1的意思就是取每个小数组中的最大值组成新的数组<p>\n",
    "axis=0: 取同一位置下有最大值的数组序号，遍历每个位置得到新的数组<p>\n",
    "简单的说，axis指定了在矩阵的哪一个维度上进行比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-17-71ccadb4572d>:1: calling argmax (from tensorflow.python.ops.math_ops) with dimension is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n"
     ]
    }
   ],
   "source": [
    "y_true_cls = tf.argmax(y_true, dimension=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积层 1\n",
    "\n",
    "创建第一个卷积层。将`x_image`当作输入，创建`num_filters1`个不同的滤波器，每个滤波器的宽高都与 `filter_size1`相等。最终我们会用2x2的max-pooling将图像降采样，使它的尺寸减半。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_conv1, weights_conv1 = \\\n",
    "    new_conv_layer(input=x_image,\n",
    "                   num_input_channels=num_channels,\n",
    "                   filter_size=filter_size1,\n",
    "                   num_filters=num_filters1,\n",
    "                   use_pooling=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检查卷积层输出张量的大小。它是（？,14, 14, 16），这代表着有任意数量的图像（？代表数量），每张图像有14个像素的宽和高，有16个不同的通道，每个滤波器各有一个通道。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu:0' shape=(?, 14, 14, 16) dtype=float32>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_conv1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积层 2\n",
    "\n",
    "创建第二个卷积层，它将第一个卷积层的输出作为输入。输入通道的数量对应着第一个卷积层的滤波数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_conv2, weights_conv2 = \\\n",
    "    new_conv_layer(input=layer_conv1,\n",
    "                   num_input_channels=num_filters1,\n",
    "                   filter_size=filter_size2,\n",
    "                   num_filters=num_filters2,\n",
    "                   use_pooling=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "核对一下这个卷积层输出张量的大小。它的大小是（？， 7， 7， 36）,其中？也代表着任意数量的图像，每张图有7像素的宽高，每个滤波器有36个通道。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_1:0' shape=(?, 7, 7, 36) dtype=float32>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_conv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 转换层\n",
    "\n",
    "这个卷积层输出一个4维张量。现在我们想将它作为一个全连接网络的输入，这就需要将它转换成2维张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_flat, num_features = flatten_layer(layer_conv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个张量的大小是（？， 1764），意味着共有一定数量的图像，每张图像被转换成长为1764的向量。其中1764 = 7 x 7 x 36。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1764"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape_1:0' shape=(?, 1764) dtype=float32>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_flat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全连接层 1\n",
    "\n",
    "往网络中添加一个全连接层。输入是一个前面卷积得到的被转换过的层。全连接层中的神经元或节点数为`fc_size`。我们可以用ReLU来学习非线性关系。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_fc1 = new_fc_layer(input=layer_flat,\n",
    "                         num_inputs=num_features,\n",
    "                         num_outputs=fc_size,\n",
    "                         use_relu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全连接层的输出是一个大小为（？，128）的张量，？代表着一定数量的图像，并且`fc_size` == 128。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_2:0' shape=(?, 128) dtype=float32>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_fc1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全连接层 2\n",
    "\n",
    "添加另外一个全连接层，它的输出是一个长度为10的向量，它确定了输入图是属于哪个类别。这层并没有用到ReLU。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_fc2 = new_fc_layer(input=layer_fc1,\n",
    "                         num_inputs=fc_size,\n",
    "                         num_outputs=num_classes,\n",
    "                         use_relu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_3:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_fc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测类别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二个全连接层估算了输入图有多大的可能属于10个类别中的其中一个。然而，这是很粗略的估计并且很难解释，因为数值可能很小或很大，因此我们会对它们做归一化，将每个元素限制在0到1之间，并且相加为1。这用一个称为softmax的函数来计算的，结果保存在`y_pred`中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tf.nn.softmax(layer_fc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "类别数字是最大元素的索引。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_cls = tf.argmax(y_pred, dimension=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 优化损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了使模型更好地对输入图像进行分类，我们必须改变`weights`和`biases`变量。首先我们需要对比模型`y_pred`的预测输出和期望输出的`y_true`，来了解目前模型的性能如何。\n",
    "\n",
    "交叉熵（cross-entropy）是在分类中使用的性能度量。交叉熵是一个常为正值的连续函数，如果模型的预测值精准地符合期望的输出，它就等于零。因此，优化的目的就是通过改变网络层的变量来最小化交叉熵。\n",
    "\n",
    "TensorFlow有一个内置的计算交叉熵的函数。这个函数内部计算了softmax，所以我们要用`layer_fc2`的输出而非直接用`y_pred`,因为`y_pred`上已经计算了softmax。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-31-2dd067a7547b>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=layer_fc2,\n",
    "                                                        labels=y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们为每个图像分类计算了交叉熵，所以有一个当前模型在每张图上表现的度量。但是为了用交叉熵来指导模型变量的优化，我们需要一个额外的标量值，因此简单地利用所有图像分类交叉熵的均值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 优化方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "既然我们有一个需要被最小化的损失度量，接着就可以建立优化一个优化器。这个例子中，我们使用的是梯度下降的变体`AdamOptimizer`。\n",
    "\n",
    "优化过程并不是在这里执行。实际上，还没计算任何东西，我们只是往TensorFlow图中添加了优化器，以便之后的操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 性能度量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们需要另外一些性能度量，来向用户展示这个过程。\n",
    "\n",
    "这是一个布尔值向量，代表预测类型是否等于每张图片的真实类型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面的计算先将布尔值向量类型转换成浮点型向量，这样子False就变成0，True变成1，然后计算这些值的平均数，以此来计算分类的准确度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 运行TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建TensorFlow会话（session）\n",
    "\n",
    "一旦创建了TensorFlow图，我们需要创建一个TensorFlow会话，用来运行图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化变量\n",
    "\n",
    "我们需要在开始优化weights和biases变量之前对它们进行初始化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用来优化迭代的帮助函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在训练集中有50,000张图。用这些图像计算模型的梯度会花很多时间。因此我们利用随机梯度下降的方法，它在优化器的每次迭代里只用到了一小部分的图像。\n",
    "\n",
    "如果内存耗尽导致电脑死机或变得很慢，你应该试着减少这些数量，但同时可能还需要更优化的迭代。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "函数执行了多次的优化迭代来逐步地提升网络层的变量。在每次迭代中，从训练集中选择一批新的数据，然后TensorFlow用这些训练样本来执行优化器。每100次迭代会打印出相关信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counter for total number of iterations performed so far.\n",
    "total_iterations = 256\n",
    "# trainPixels = trainPixels.values\n",
    "# print(trainPixels.values)\n",
    "\n",
    "def optimize(num_iterations):\n",
    "    # Ensure we update the global variable rather than a local copy.\n",
    "    global total_iterations\n",
    "\n",
    "    # Start-time used for printing time-usage below.\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i in range(total_iterations,\n",
    "                   total_iterations + num_iterations):\n",
    "        # Get a batch of training examples.\n",
    "        # x_batch now holds a batch of images and\n",
    "        # y_true_batch are the true labels for those images.\n",
    "\n",
    "        index = random.randint(0,41936)\n",
    "        x_batch = trainPixels[index:index + 64]\n",
    "        y_true_batch = onehot_labels[index:index + 64]\n",
    "        \n",
    "        # Put the batch into a dict with the proper names\n",
    "        # for placeholder variables in the TensorFlow graph.\n",
    "        feed_dict_train = {x: x_batch,\n",
    "                           y_true: y_true_batch}\n",
    "\n",
    "        # Run the optimizer using this batch of training data.\n",
    "        # TensorFlow assigns the variables in feed_dict_train\n",
    "        # to the placeholder variables and then runs the optimizer.\n",
    "        session.run(optimizer, feed_dict=feed_dict_train)\n",
    "\n",
    "        # Print status every 100 iterations.\n",
    "        if i % 100 == 0:\n",
    "            # Calculate the accuracy on the training-set.\n",
    "            acc = session.run(accuracy, feed_dict=feed_dict_train)\n",
    "\n",
    "            # Message for printing.\n",
    "            msg = \"Optimization Iteration: {0:>6}, Training Accuracy: {1:>6.1%}\"\n",
    "\n",
    "            # Print it.\n",
    "            print(msg.format(i + 1, acc))\n",
    "\n",
    "    # Update the total number of iterations performed.\n",
    "    total_iterations += num_iterations\n",
    "\n",
    "    # Ending time.\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Difference between start and end-times.\n",
    "    time_dif = end_time - start_time\n",
    "\n",
    "    # Print the time-usage.\n",
    "    print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10,000次优化迭代后的性能\n",
    "\n",
    "经过10,000次优化迭代后，测试集上的分类准确率高达99%。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:    301, Training Accuracy:  54.7%\n",
      "Optimization Iteration:    401, Training Accuracy:  87.5%\n",
      "Optimization Iteration:    501, Training Accuracy:  85.9%\n",
      "Optimization Iteration:    601, Training Accuracy:  90.6%\n",
      "Optimization Iteration:    701, Training Accuracy:  93.8%\n",
      "Optimization Iteration:    801, Training Accuracy:  90.6%\n",
      "Optimization Iteration:    901, Training Accuracy:  96.9%\n",
      "Optimization Iteration:   1001, Training Accuracy:  92.2%\n",
      "Optimization Iteration:   1101, Training Accuracy:  95.3%\n",
      "Optimization Iteration:   1201, Training Accuracy:  93.8%\n",
      "Optimization Iteration:   1301, Training Accuracy:  92.2%\n",
      "Optimization Iteration:   1401, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   1501, Training Accuracy:  95.3%\n",
      "Optimization Iteration:   1601, Training Accuracy:  93.8%\n",
      "Optimization Iteration:   1701, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   1801, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   1901, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   2001, Training Accuracy:  96.9%\n",
      "Optimization Iteration:   2101, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   2201, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   2301, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   2401, Training Accuracy:  96.9%\n",
      "Optimization Iteration:   2501, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   2601, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   2701, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   2801, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   2901, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   3001, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   3101, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   3201, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   3301, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   3401, Training Accuracy:  96.9%\n",
      "Optimization Iteration:   3501, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   3601, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   3701, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   3801, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   3901, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   4001, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4101, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4201, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4301, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4401, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   4501, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   4601, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4701, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4801, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   4901, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5001, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   5101, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5201, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5301, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5401, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   5501, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   5601, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5701, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5801, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5901, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6001, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6101, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6201, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6301, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6401, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   6501, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6601, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   6701, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6801, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6901, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7001, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7101, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7201, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   7301, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7401, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7501, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7601, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7701, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7801, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7901, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8001, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8101, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8201, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8301, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8401, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8501, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8601, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8701, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8801, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8901, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   9001, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   9101, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   9201, Training Accuracy: 100.0%\n",
      "Time usage: 0:01:07\n"
     ]
    }
   ],
   "source": [
    "optimize(num_iterations=9000) # We performed 1000 iterations above. [9000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "argmaxtensor = tf.argmax(y_pred, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 784)\n"
     ]
    }
   ],
   "source": [
    "# session.run(tf.global_variables_initializer())\n",
    "# softmax_tensor = session.graph.get_tensor_by_name('final_result:0')\n",
    "test = pd.read_csv(\"data/test.csv\")\n",
    "print(test.shape)\n",
    "test.head()\n",
    "test = test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputPic = test[99].reshape(28,28)\n",
    "plt.imshow(inputPic, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "feed_dict = {x: test[99].reshape(1,784)}\n",
    "y_pred = session.run(argmaxtensor, feed_dict=feed_dict)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answers = []\n",
    "\n",
    "# for img in test:\n",
    "#     feed_dict = {x: img.reshape(1,784)}\n",
    "#     y_pred = session.run(argmaxtensor, feed_dict=feed_dict)\n",
    "#     answers.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(answers[27999])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们已经用TensorFlow完成了任务，关闭session，释放资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This has been commented out in case you want to modify and experiment\n",
    "# with the Notebook without having to restart it.\n",
    "# session.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "575px",
    "left": "1009px",
    "right": "20px",
    "top": "108px",
    "width": "510px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
