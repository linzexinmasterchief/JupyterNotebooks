{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用Python3.5.2（Anaconda）开发，TensorFlow版本是："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经网络的配置\n",
    "\n",
    "方便起见，在这里定义神经网络的配置，你可以很容易找到或改变这些数值，然后重新运行Notebook。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convolutional Layer 1.\n",
    "filter_size1 = 5          # Convolution filters are 5 x 5 pixels.\n",
    "num_filters1 = 16         # There are 16 of these filters.\n",
    "\n",
    "# Convolutional Layer 2.\n",
    "filter_size2 = 5          # Convolution filters are 5 x 5 pixels.\n",
    "num_filters2 = 36         # There are 36 of these filters.\n",
    "\n",
    "# Fully-connected layer.\n",
    "fc_size = 128             # Number of neurons in fully-connected layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 载入数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST数据集大约12MB，如果没在文件夹中找到就会自动下载。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"data/train.csv\")\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# trainLabels is y_train\n",
    "train[\"label\"] = train[\"label\"].astype('int32')\n",
    "trainLabels = train[\"label\"]\n",
    "\n",
    "# Drop 'label' column\n",
    "# train pixels is x_train\n",
    "trainPixels = train.drop(labels = [\"label\"],axis = 1)\n",
    "# free some space\n",
    "del train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainPixels = trainPixels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as ses:\n",
    "    NUM_CLASSES = 10\n",
    "\n",
    "    labels = trainLabels\n",
    "    onehot_labels = tf.one_hot(labels, depth=10, on_value=None, off_value=None, axis=None, dtype=None, name=None).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在下面的源码中，有很多地方用到了数据维度。它们只在一个地方定义，因此我们可以在代码中使用这些数字而不是直接写数字。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We know that MNIST images are 28 pixels in each dimension.\n",
    "img_size = 28\n",
    "\n",
    "# Images are stored in one-dimensional arrays of this length.\n",
    "img_size_flat = img_size * img_size\n",
    "\n",
    "# Tuple with height and width of images used to reshape arrays.\n",
    "img_shape = (img_size, img_size)\n",
    "\n",
    "# Number of colour channels for the images: 1 channel for gray-scale.\n",
    "num_channels = 1\n",
    "\n",
    "# Number of classes, one class for each of 10 digits.\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "函数用来根据给定大小创建TensorFlow变量，并将它们用随机值初始化。需注意的是在此时并未完成初始化工作，仅仅是在TensorFlow图里定义它们。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_biases(length):\n",
    "    return tf.Variable(tf.constant(0.05, shape=[length]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建卷积层的帮助函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个函数为TensorFlow在计算图里创建了新的卷积层。这里并没有执行什么计算，只是在TensorFlow图里添加了数学公式。\n",
    "\n",
    "假设输入的是四维的张量，各个维度如下：\n",
    "\n",
    "1. 图像数量\n",
    "2. 每张图像的Y轴\n",
    "3. 每张图像的X轴\n",
    "4. 每张图像的通道数\n",
    "\n",
    "输入通道可能是彩色通道，当输入是前面的卷积层生成的时候，它也可能是滤波通道。\n",
    "\n",
    "输出是另外一个4通道的张量，如下：\n",
    "\n",
    "1. 图像数量，与输入相同\n",
    "2. 每张图像的Y轴。如果用到了2x2的池化，是输入图像宽高的一半。\n",
    "3. 每张图像的X轴。同上。\n",
    "4. 卷积滤波生成的通道数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_conv_layer(input,              # The previous layer.\n",
    "                   num_input_channels, # Num. channels in prev. layer.\n",
    "                   filter_size,        # Width and height of each filter.\n",
    "                   num_filters,        # Number of filters.\n",
    "                   use_pooling=True):  # Use 2x2 max-pooling.\n",
    "\n",
    "    # Shape of the filter-weights for the convolution.\n",
    "    # This format is determined by the TensorFlow API.\n",
    "    shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "\n",
    "    # Create new weights aka. filters with the given shape.\n",
    "    weights = new_weights(shape=shape)\n",
    "\n",
    "    # Create new biases, one for each filter.\n",
    "    biases = new_biases(length=num_filters)\n",
    "\n",
    "    # Create the TensorFlow operation for convolution.\n",
    "    # Note the strides are set to 1 in all dimensions.\n",
    "    # The first and last stride must always be 1,\n",
    "    # because the first is for the image-number and\n",
    "    # the last is for the input-channel.\n",
    "    # But e.g. strides=[1, 2, 2, 1] would mean that the filter\n",
    "    # is moved 2 pixels across the x- and y-axis of the image.\n",
    "    # The padding is set to 'SAME' which means the input image\n",
    "    # is padded with zeroes so the size of the output is the same.\n",
    "    layer = tf.nn.conv2d(input=input,\n",
    "                         filter=weights,\n",
    "                         strides=[1, 1, 1, 1],\n",
    "                         padding='SAME')\n",
    "\n",
    "    # Add the biases to the results of the convolution.\n",
    "    # A bias-value is added to each filter-channel.\n",
    "    layer += biases\n",
    "\n",
    "    # Use pooling to down-sample the image resolution?\n",
    "    if use_pooling:\n",
    "        # This is 2x2 max-pooling, which means that we\n",
    "        # consider 2x2 windows and select the largest value\n",
    "        # in each window. Then we move 2 pixels to the next window.\n",
    "        layer = tf.nn.max_pool(value=layer,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME')\n",
    "\n",
    "    # Rectified Linear Unit (ReLU).\n",
    "    # It calculates max(x, 0) for each input pixel x.\n",
    "    # This adds some non-linearity to the formula and allows us\n",
    "    # to learn more complicated functions.\n",
    "    layer = tf.nn.relu(layer)\n",
    "\n",
    "    # Note that ReLU is normally executed before the pooling,\n",
    "    # but since relu(max_pool(x)) == max_pool(relu(x)) we can\n",
    "    # save 75% of the relu-operations by max-pooling first.\n",
    "\n",
    "    # We return both the resulting layer and the filter-weights\n",
    "    # because we will plot the weights later.\n",
    "    return layer, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 转换一个层的帮助函数\n",
    "\n",
    "卷积层生成了4维的张量。我们会在卷积层之后添加一个全连接层，因此我们需要将这个4维的张量转换成可被全连接层使用的2维张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten_layer(layer):\n",
    "    # Get the shape of the input layer.\n",
    "    layer_shape = layer.get_shape()\n",
    "\n",
    "    # The shape of the input layer is assumed to be:\n",
    "    # layer_shape == [num_images, img_height, img_width, num_channels]\n",
    "\n",
    "    # The number of features is: img_height * img_width * num_channels\n",
    "    # We can use a function from TensorFlow to calculate this.\n",
    "    num_features = layer_shape[1:4].num_elements()\n",
    "    \n",
    "    # Reshape the layer to [num_images, num_features].\n",
    "    # Note that we just set the size of the second dimension\n",
    "    # to num_features and the size of the first dimension to -1\n",
    "    # which means the size in that dimension is calculated\n",
    "    # so the total size of the tensor is unchanged from the reshaping.\n",
    "    layer_flat = tf.reshape(layer, [-1, num_features])\n",
    "\n",
    "    # The shape of the flattened layer is now:\n",
    "    # [num_images, img_height * img_width * num_channels]\n",
    "\n",
    "    # Return both the flattened layer and the number of features.\n",
    "    return layer_flat, num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建一个全连接层的帮助函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个函数为TensorFlow在计算图中创建了一个全连接层。这里也不进行任何计算，只是往TensorFlow图中添加数学公式。\n",
    "\n",
    "输入是大小为`[num_images, num_inputs]`的二维张量。输出是大小为`[num_images, num_outputs]`的2维张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_fc_layer(input,          # The previous layer.\n",
    "                 num_inputs,     # Num. inputs from prev. layer.\n",
    "                 num_outputs,    # Num. outputs.\n",
    "                 use_relu=True): # Use Rectified Linear Unit (ReLU)?\n",
    "\n",
    "    # Create new weights and biases.\n",
    "    weights = new_weights(shape=[num_inputs, num_outputs])\n",
    "    biases = new_biases(length=num_outputs)\n",
    "\n",
    "    # Calculate the layer as the matrix multiplication of\n",
    "    # the input and weights, and then add the bias-values.\n",
    "    layer = tf.matmul(input, weights) + biases\n",
    "\n",
    "    # Use ReLU?\n",
    "    if use_relu:\n",
    "        layer = tf.nn.relu(layer)\n",
    "\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 占位符 （Placeholder）变量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Placeholder是作为图的输入，每次我们运行图的时候都可能会改变它们。将这个过程称为feeding placeholder变量，后面将会描述它。\n",
    "\n",
    "首先我们为输入图像定义placeholder变量。这让我们可以改变输入到TensorFlow图中的图像。这也是一个张量（tensor），代表一个多维向量或矩阵。数据类型设置为float32，形状设为`[None, img_size_flat]`，`None`代表tensor可能保存着任意数量的图像，每张图象是一个长度为`img_size_flat`的向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "卷积层希望`x`被编码为4维张量，因此我们需要将它的形状转换至`[num_images, img_height, img_width, num_channels]`。注意`img_height == img_width == img_size`，如果第一维的大小设为-1， `num_images`的大小也会被自动推导出来。转换运算如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x, [-1, img_size, img_size, num_channels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我们为输入变量`x`中的图像所对应的真实标签定义placeholder变量。变量的形状是`[None, num_classes]`，这代表着它保存了任意数量的标签，每个标签是长度为`num_classes`的向量，本例中长度为10。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true = tf.placeholder(tf.float32, shape=[None, 10], name='y_true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们也可以为class-number提供一个placeholder，但这里用argmax来计算它。这里只是TensorFlow中的一些操作，没有执行什么运算。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.argmax(array, dimension=1) = np.argmax(array, axis=1)<p>\n",
    "如果array是多维数组，dimemsion或axis=1的意思就是取每个小数组中的最大值组成新的数组<p>\n",
    "axis=0: 取同一位置下有最大值的数组序号，遍历每个位置得到新的数组<p>\n",
    "简单的说，axis指定了在矩阵的哪一个维度上进行比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true_cls = tf.argmax(y_true, dimension=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积层 1\n",
    "\n",
    "创建第一个卷积层。将`x_image`当作输入，创建`num_filters1`个不同的滤波器，每个滤波器的宽高都与 `filter_size1`相等。最终我们会用2x2的max-pooling将图像降采样，使它的尺寸减半。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_conv1, weights_conv1 = \\\n",
    "    new_conv_layer(input=x_image,\n",
    "                   num_input_channels=num_channels,\n",
    "                   filter_size=filter_size1,\n",
    "                   num_filters=num_filters1,\n",
    "                   use_pooling=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检查卷积层输出张量的大小。它是（？,14, 14, 16），这代表着有任意数量的图像（？代表数量），每张图像有14个像素的宽和高，有16个不同的通道，每个滤波器各有一个通道。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_3:0' shape=(?, 14, 14, 16) dtype=float32>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_conv1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积层 2\n",
    "\n",
    "创建第二个卷积层，它将第一个卷积层的输出作为输入。输入通道的数量对应着第一个卷积层的滤波数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_conv2, weights_conv2 = \\\n",
    "    new_conv_layer(input=layer_conv1,\n",
    "                   num_input_channels=num_filters1,\n",
    "                   filter_size=filter_size2,\n",
    "                   num_filters=num_filters2,\n",
    "                   use_pooling=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "核对一下这个卷积层输出张量的大小。它的大小是（？， 7， 7， 36）,其中？也代表着任意数量的图像，每张图有7像素的宽高，每个滤波器有36个通道。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_4:0' shape=(?, 7, 7, 36) dtype=float32>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_conv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 转换层\n",
    "\n",
    "这个卷积层输出一个4维张量。现在我们想将它作为一个全连接网络的输入，这就需要将它转换成2维张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_flat, num_features = flatten_layer(layer_conv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个张量的大小是（？， 1764），意味着共有一定数量的图像，每张图像被转换成长为1764的向量。其中1764 = 7 x 7 x 36。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1764"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape_3:0' shape=(?, 1764) dtype=float32>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_flat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全连接层 1\n",
    "\n",
    "往网络中添加一个全连接层。输入是一个前面卷积得到的被转换过的层。全连接层中的神经元或节点数为`fc_size`。我们可以用ReLU来学习非线性关系。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_fc1 = new_fc_layer(input=layer_flat,\n",
    "                         num_inputs=num_features,\n",
    "                         num_outputs=fc_size,\n",
    "                         use_relu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全连接层的输出是一个大小为（？，128）的张量，？代表着一定数量的图像，并且`fc_size` == 128。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_5:0' shape=(?, 128) dtype=float32>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_fc1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全连接层 2\n",
    "\n",
    "添加另外一个全连接层，它的输出是一个长度为10的向量，它确定了输入图是属于哪个类别。这层并没有用到ReLU。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_fc2 = new_fc_layer(input=layer_fc1,\n",
    "                         num_inputs=fc_size,\n",
    "                         num_outputs=num_classes,\n",
    "                         use_relu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_7:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_fc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测类别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二个全连接层估算了输入图有多大的可能属于10个类别中的其中一个。然而，这是很粗略的估计并且很难解释，因为数值可能很小或很大，因此我们会对它们做归一化，将每个元素限制在0到1之间，并且相加为1。这用一个称为softmax的函数来计算的，结果保存在`y_pred`中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = tf.nn.softmax(layer_fc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "类别数字是最大元素的索引。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_cls = tf.argmax(y_pred, dimension=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 优化损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了使模型更好地对输入图像进行分类，我们必须改变`weights`和`biases`变量。首先我们需要对比模型`y_pred`的预测输出和期望输出的`y_true`，来了解目前模型的性能如何。\n",
    "\n",
    "交叉熵（cross-entropy）是在分类中使用的性能度量。交叉熵是一个常为正值的连续函数，如果模型的预测值精准地符合期望的输出，它就等于零。因此，优化的目的就是通过改变网络层的变量来最小化交叉熵。\n",
    "\n",
    "TensorFlow有一个内置的计算交叉熵的函数。这个函数内部计算了softmax，所以我们要用`layer_fc2`的输出而非直接用`y_pred`,因为`y_pred`上已经计算了softmax。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=layer_fc2,\n",
    "                                                        labels=y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们为每个图像分类计算了交叉熵，所以有一个当前模型在每张图上表现的度量。但是为了用交叉熵来指导模型变量的优化，我们需要一个额外的标量值，因此简单地利用所有图像分类交叉熵的均值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 优化方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "既然我们有一个需要被最小化的损失度量，接着就可以建立优化一个优化器。这个例子中，我们使用的是梯度下降的变体`AdamOptimizer`。\n",
    "\n",
    "优化过程并不是在这里执行。实际上，还没计算任何东西，我们只是往TensorFlow图中添加了优化器，以便之后的操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 性能度量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们需要另外一些性能度量，来向用户展示这个过程。\n",
    "\n",
    "这是一个布尔值向量，代表预测类型是否等于每张图片的真实类型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面的计算先将布尔值向量类型转换成浮点型向量，这样子False就变成0，True变成1，然后计算这些值的平均数，以此来计算分类的准确度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 运行TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建TensorFlow会话（session）\n",
    "\n",
    "一旦创建了TensorFlow图，我们需要创建一个TensorFlow会话，用来运行图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化变量\n",
    "\n",
    "我们需要在开始优化weights和biases变量之前对它们进行初始化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用来优化迭代的帮助函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在训练集中有50,000张图。用这些图像计算模型的梯度会花很多时间。因此我们利用随机梯度下降的方法，它在优化器的每次迭代里只用到了一小部分的图像。\n",
    "\n",
    "如果内存耗尽导致电脑死机或变得很慢，你应该试着减少这些数量，但同时可能还需要更优化的迭代。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "函数执行了多次的优化迭代来逐步地提升网络层的变量。在每次迭代中，从训练集中选择一批新的数据，然后TensorFlow用这些训练样本来执行优化器。每100次迭代会打印出相关信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Counter for total number of iterations performed so far.\n",
    "total_iterations = 256\n",
    "# trainPixels = trainPixels.values\n",
    "# print(trainPixels.values)\n",
    "\n",
    "def optimize(num_iterations):\n",
    "    # Ensure we update the global variable rather than a local copy.\n",
    "    global total_iterations\n",
    "\n",
    "    # Start-time used for printing time-usage below.\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i in range(total_iterations,\n",
    "                   total_iterations + num_iterations):\n",
    "        # Get a batch of training examples.\n",
    "        # x_batch now holds a batch of images and\n",
    "        # y_true_batch are the true labels for those images.\n",
    "\n",
    "        index = random.randint(0,41936)\n",
    "        x_batch = trainPixels[index:index + 64]\n",
    "        y_true_batch = onehot_labels[index:index + 64]\n",
    "        \n",
    "        # Put the batch into a dict with the proper names\n",
    "        # for placeholder variables in the TensorFlow graph.\n",
    "        feed_dict_train = {x: x_batch,\n",
    "                           y_true: y_true_batch}\n",
    "\n",
    "        # Run the optimizer using this batch of training data.\n",
    "        # TensorFlow assigns the variables in feed_dict_train\n",
    "        # to the placeholder variables and then runs the optimizer.\n",
    "        session.run(optimizer, feed_dict=feed_dict_train)\n",
    "\n",
    "        # Print status every 100 iterations.\n",
    "        if i % 100 == 0:\n",
    "            # Calculate the accuracy on the training-set.\n",
    "            acc = session.run(accuracy, feed_dict=feed_dict_train)\n",
    "\n",
    "            # Message for printing.\n",
    "            msg = \"Optimization Iteration: {0:>6}, Training Accuracy: {1:>6.1%}\"\n",
    "\n",
    "            # Print it.\n",
    "            print(msg.format(i + 1, acc))\n",
    "\n",
    "    # Update the total number of iterations performed.\n",
    "    total_iterations += num_iterations\n",
    "\n",
    "    # Ending time.\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Difference between start and end-times.\n",
    "    time_dif = end_time - start_time\n",
    "\n",
    "    # Print the time-usage.\n",
    "    print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10,000次优化迭代后的性能\n",
    "\n",
    "经过10,000次优化迭代后，测试集上的分类准确率高达99%。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:    301, Training Accuracy:  67.2%\n",
      "Optimization Iteration:    401, Training Accuracy:  82.8%\n",
      "Optimization Iteration:    501, Training Accuracy:  90.6%\n",
      "Optimization Iteration:    601, Training Accuracy:  95.3%\n",
      "Optimization Iteration:    701, Training Accuracy:  95.3%\n",
      "Optimization Iteration:    801, Training Accuracy:  95.3%\n",
      "Optimization Iteration:    901, Training Accuracy:  95.3%\n",
      "Optimization Iteration:   1001, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   1101, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   1201, Training Accuracy:  93.8%\n",
      "Optimization Iteration:   1301, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   1401, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   1501, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   1601, Training Accuracy:  96.9%\n",
      "Optimization Iteration:   1701, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   1801, Training Accuracy:  96.9%\n",
      "Optimization Iteration:   1901, Training Accuracy:  95.3%\n",
      "Optimization Iteration:   2001, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   2101, Training Accuracy:  96.9%\n",
      "Optimization Iteration:   2201, Training Accuracy:  96.9%\n",
      "Optimization Iteration:   2301, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   2401, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   2501, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   2601, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   2701, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   2801, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   2901, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   3001, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   3101, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   3201, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   3301, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   3401, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   3501, Training Accuracy:  96.9%\n",
      "Optimization Iteration:   3601, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   3701, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   3801, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   3901, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   4001, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4101, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   4201, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4301, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4401, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4501, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4601, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4701, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4801, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4901, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5001, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5101, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5201, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   5301, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5401, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5501, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5601, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5701, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5801, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   5901, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6001, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6101, Training Accuracy:  96.9%\n",
      "Optimization Iteration:   6201, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   6301, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6401, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6501, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6601, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6701, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6801, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6901, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7001, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7101, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7201, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7301, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7401, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7501, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7601, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7701, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7801, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7901, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8001, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8101, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8201, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8301, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8401, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8501, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8601, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8701, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8801, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   8901, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   9001, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   9101, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   9201, Training Accuracy: 100.0%\n",
      "Time usage: 0:00:57\n"
     ]
    }
   ],
   "source": [
    "optimize(num_iterations=9000) # We performed 1000 iterations above. [9000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "argmaxtensor = tf.argmax(y_pred, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 784)\n"
     ]
    }
   ],
   "source": [
    "# session.run(tf.global_variables_initializer())\n",
    "# softmax_tensor = session.graph.get_tensor_by_name('final_result:0')\n",
    "test = pd.read_csv(\"data/test.csv\")\n",
    "print(test.shape)\n",
    "test.head()\n",
    "test = test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputPic = test[2].reshape(28,28)\n",
    "plt.imshow(inputPic, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9]\n"
     ]
    }
   ],
   "source": [
    "feed_dict = {x: test[2].reshape(1,784)}\n",
    "y_pred = session.run(argmaxtensor, feed_dict=feed_dict)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# answers = []\n",
    "\n",
    "# for img in test:\n",
    "#     feed_dict = {x: img.reshape(1,784)}\n",
    "#     y_pred = session.run(argmaxtensor, feed_dict=feed_dict)\n",
    "#     answers.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(answers[27999])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们已经用TensorFlow完成了任务，关闭session，释放资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This has been commented out in case you want to modify and experiment\n",
    "# with the Notebook without having to restart it.\n",
    "# session.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "575px",
    "left": "1009px",
    "right": "20px",
    "top": "108px",
    "width": "510px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
